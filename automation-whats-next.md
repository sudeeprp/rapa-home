# Automation

In every cycle of automation, something repeatable is removed from human effort. The result has been the transition from manual labor to the pursuit of higher-order goals - From farming to reading. From safeguarding wealth to investing it.
The higher-order work requires so-called ‘intelligence’

Some intelligence is getting automated now - As in problem-solving, like breaking down a big problem, applying patterns/prior art to solve it. LLMs can do some of this with AI agents. And they keep getting better.
So what's next? Suppose a machine can find every known answer (instead of a human remembering it), and it can repeat known patterns of problem-solving (instead of relying on experienced humans). What’s a higher-order activity for us humans?

Perhaps inquisitiveness - “asking the question” is the higher-order activity? Coupled with critical thinking to be skeptical about the answer? The conviction to drive with intent? And the discipline to follow through?

**The hypothesis**: These things aren't to be found outside; they are within us. So is the new skill to look within ourselves?

## Strengths of the hypothesis

The progression from manual labor to abstract problem-solving mirrors historical technological shifts. Framing LLMs and AI agents as problem-solvers on par with human “intelligence” accurately reflects their growing capabilities.
The conclusion—that the next frontier is generating meaningful questions, not just finding answers—echoes contemporary thought around human creativity, curiosity, and meta-cognition as increasingly vital skills.

## Points to Challenge

1. Assumption of answer-availability: While LLMs and agents can generate many answers, they are always bounded by data and context. The idea that "it can find every known answer" may underestimate the depth, subjectivity, and ambiguity inherent in many domains.
1. Question-asking as higher-order: Proposing that asking questions is the next higher-order goal is both insightful and limiting. Other “higher-order” skills can be: interpreting and synthesizing, empathy, ethical reasoning, and collaborative creation.
1. Skill to “Look Within”: The inward turn towards self-reflection and self-knowledge is ancient but remains powerful in this context. However, critiques from psychology and social science suggest much of self is constructed socially—not just internally.
1. Discipline and Skepticism: Rigor, persistence, and critical evaluation are vital when AI can generate plausible but inaccurate answers. However, you could also address the skill of building frameworks for collective wisdom, not just personal insight.

## Areas to explore

1. Explore how the skills of generating questions, sense-making, and creating perspectives might interplay and become new domains for both individual and collective advancement.
1. What activity can build these skills, so we remain relevant even when large parts of "intelligence" are automated?

### What Skills Remain Human

- Sense-Making and Valuation: Interpreting ambiguous data, weighing trade-offs, and forming value judgments demand intuition.​
- Embodied and Social Cognition: Insights arise from interacting physically with the environment or through genuine social engagement, not just mixing words or notes.​
- Ethics, Empathy, and Motivation: They are outside purely algorithmic reasoning, and are fundamental to fields like leadership, therapy, and art.​
- Problem-Finding and Creativity: Humans can invent new problems and imagine what does not yet exist—making leaps beyond any data or precedent.

References:

- [Limits of AI in graphic design](https://nicolesteffen.com/2023/05/28/the-limits-of-artificial-intelligence-in-graphic-design-why-ai-cannot-be-truly-creative-yet/) lists divergent thinking (deviating from established ways),
intuition (coming from personal experience), aesthetic sense and emotions as uniquely human skills.
- [6 Critical Human Skills](https://www.linkedin.com/business/talent/blog/learning-and-development/human-skills-age-of-ai) lists critical thinking and empathy,
also mentioning that they are undervalued. Part of those 'soft' skills are mindful dialogue, interpersonal-communication, relationship-building

### What's the use of being human

Yes, humans who can touch-and-feel are different from machines. However, if machines can make data-driven decisions to maximize outcomes, is there any use of humans? What must a human do, to stay relevant?

Let's ground this in practical situations that have some ambiguity in them.

Case in point: Consider two cases, one from a people-management and another from a product-management perspective.

**People management**: Say I have a software team, and I need to make rules regarding hybrid work. I feed the team's background, the organization-goal, and other relevant information into an LLM.
It would suggest what most humans would do, to maximize towards organization goals. if I go accordingly, then I'm not needed - the LLM can frame the rules.
If I take a decision not driven by any of these, it may make me human. But that would make me arbitrary. And maybe harm the organization objectives.

Empathy is often quoted as a human trait, which machines don't have. Does empathy play a role here?
[Leading with empathy](https://www.innovativehumancapital.com/article/leading-with-empathy-how-understanding-others-creates-connection-and-drives-success) illustrates empathy's role in driving connection, trust and motivation.
It lists techniques like active-listening and perspective-taking as ways to build this skill.

Continuing the anecdote, say the LLM suggested a policy where teams need to be in office three days a week, going by the current industry trend.
However, there's someone in the team needing to care for a child at home.
The LLM-style response may be "It’s understandable to face challenges balancing new parenthood and work. Consider flexible options or reduced hours. Here are some available resources to help".

What just happened here? Empathetic LLMs.
[Deliberate Directions](https://deliberatedirections.com/empathy-in-leadership-guide/) lists techniques to use empathy for strategic objectives. [LLMs in healthcare setting](https://www.jmir.org/2024/1/e52597/)
indicates that the LLM output showed more empathy in many cases.
In another set of studies, [evaluators perceived AI as more compassionate than expert humans](https://www.nature.com/articles/s44271-024-00182-6).

Let's now construct a higher-order human response: Suppose the person had shared an experience - Parenting may be rewarding, but they missed the 'belonging-ness' that teamwork brings.
So in addition to the LLM-style response, the manager asks for ways they can help retain the connection? Just to listen, with no pressure to change. With the intention to pull the team together to help if needed.
Such an interaction builds trust in a way that machines would not be able to manage

So what just happened? What made this interaction happen? What's the space in which a person shares their subtle feelings? Does it depend on my skills, or my 'soft skills' training? or my intentions?

**TODO** link 'intention' to 'creating space', which is independent of our past, which we must uncover within ourselves.
